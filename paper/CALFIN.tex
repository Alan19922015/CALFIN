%%Main takeaway - we provide calving front locations, and have automated it
%Some may be more interested in the data, or the method, so make sure we cover both

\documentclass[tc, manuscript]{copernicus}

\usepackage{wrapfig}

\begin{document}

\title{Calving Front Machine (CALFIN): Automated Calving Front Mask Dataset and Methodology for East/West Greenland, 1972-2019}

\Author[1]{Daniel}{Cheng}
\Author[1]{Yara}{Mohajerani}
\Author[2]{Michael}{Wood}
\Author[1]{Isabella}{Velicogna}
\Author[2]{Eric}{Larour}
\Author[1]{Wayne}{Hayes}

\affil[1]{University of California at Irvine, Irvine CA, USA}
\affil[2]{Jet Propulsion Laboratory, California Institute of Technology, Pasadena CA, USA}

\runningtitle{TEXT}

\runningauthor{TEXT}

\correspondence{Daniel Cheng (dlcheng@uci.edu)}

\received{}
\pubdiscuss{} %% only important for two-stage journals
\revised{}
\accepted{}
\published{}

\maketitle

\begin{abstract}
We present Calving Front Machine (CALFIN), a dataset of calving front masks for glaciers along West Greenland. The dataset is generated from Landsat imagery over the period 1972 to 2019. This dataset is unique in scope, and provides new constraints on glacial evolution over the time period. The current iteration offers a new opportunity to explore previous trends and validate existing models, enabling more accurate predictions moving forward.

The dataset is contains data that is automatically generated. We generate the vectorized calving fronts from raw Landsat imagery. Our method utilizes deep learning in the form of a neural network. This approach builds on existing work \citep{mohajerani2019} \citep{zhang2019} \citep{baumhoer2019}. The network itself is derived from U-Net/DeeplabV3+ Xception architectures \citep{ronneberger2015} \citep{chen2018} . Additional post-processing techniques allow our method to achieve accurate and useful segmentation of raw images into Shapefile outputs. This methodology is uniquely robust to clouds, illumination differences, ice mélange, and Landsat-7 scan-line errors/data coverage gaps.

We perform an analysis of CALFIN results, which approach human levels of accuracy in comparison to manually delineated fronts. Additionally, we perform a model inter-comparison to evaluate the robustness of CALFIN's performance and cross-validate it against existing methodologies. %TODO/Save for future paper? We show the applicability of CALFIN's methodology to SAR data, Antarctic glaciers, as well as non-marine terminating glaciers.

At this stage, we seek feedback from the community and welcome any critiques or questions regarding the dataset and/or our methods. This work was conducted as a collaboration between NASA’s Jet Propulsion Laboratory and the University of California, Irvine.
\citep{paravolidakis2016}
\citep{malik2001}
\citep{ronneberger2015}
\citep{iglovikov2018}
\citep{chollet2016}
\citep{chen2017}
\citep{chen2018}
\citep{bjork2015}
\citep{mohajerani2019}
\citep{zhang2019}
\citep{baumhoer2019}
\citep{xie2015}
\citep{garcia2012}
\citep{enveo2017}

\end{abstract}

\introduction
%Introduction
The evolution of Greenland's tidewater glaciers is an important constraint on the evolution of the Greenland Ice Sheet as a whole. Likewise, changes in the Greenland are important in tracking and predicting changes in the climate overall. Constraining Greenland's glacial evolution is thus an important part of improving our understanding of Earth's climate.

%Comment out subsection headers?
\subsection{Motivation}
One such constraint on glacial evolution is the position of glacial calving fronts over time. However, delineating the calving fronts of marine-terminating glaciers is typically a time-intensive manual process. As a result, many glaciers receive less labeling than is ideal, or none at all. Additionally, existing glaciers that do receive annual labeling do not capture intra-annual variability. 

The need for an improved methodology is apparent. An automated methodology allows for the solution to previously stated issues. However, the automation of glacial calving front delineation is non-trivial. Confounding issues - such as cloud cover, ice mélange, shadowing,  - present an impediment to naive techniques such as edge detection and texture analysis. Ultimately, emerging techniques in computer science provide a promising approach to this problem. More specifically, machine learning and deep neural networks provide a robust, scalable, and accurate method to automatically delineate tidewater glacial calving fronts.

\subsection{Methodology}
In this study, we evaluate automated methods of delineating glacial termini. The glaciers studied are located along East/West Greenland. They include Helheim, Kangerlussuaq, Kong Oscar, Hayes, Rink Isbrae, Upernavik, Jakobshavn, Kangiata Nunata, and 58 other nearby glaciers. The intra-annual time series studied spans from 1972 to June 2019. Our source data is the Landsat Near Infrared (NIR) band.

We determine that convolutional neural networks present the most promising automated methodology. We determine that the UNet-inspired DeeplabV3+ architecture, with Xception backbone, is the most promising neural network architecture. We release a modified version of the DeeplabV3+ network, along with the final weights we use for data production. We release a set of data products, Calving Front Machine (CALFIN), which consists of both calving front masks as well as Shapefile polylines for the 88 glacial basins along East/West Greenland.

\subsection{Existing Work}
Existing efforts have been made by ESA's climate Change Initiative to provide calving front locations for 26 Greenlandic basins, from 1990-2016\citep{enveo2017}. Additionally, there are growing efforts to provide a unified database of manually delineated calving fronts. Nonetheless, the constant addition of new data, as well as the current scarcity of shared data, implies a consistent and repeated need for new data assimilation efforts.

We evaluate existing work in the field, performed by Yara Mohajerani, Enze Zhang, and Celia Baumhoer. These studies offer the potential to cross-validate the viability of our own methods.

\subsection{Takeaways}
Our main takeaway is the viability of generalized neural networks for automated calving front detection. Specifically, a well trained network is able to approach human levels of accuracy in picking out arbitrary glacial calving fronts. This demonstration of learning also lends credence to this methodology as a viable approach to other data assimilation tasks.

Our key goal is to provide high spatial accuracy, dense temporal resolution, and %%Main takeaway - we provide calving front locations, and have automated it
%Some may be more interested in the data, or the method, so make sure we cover both

\documentclass[tc, manuscript]{copernicus}

\usepackage{wrapfig}

\begin{document}

\title{Calving Front Machine (CALFIN): Automated Calving Front Mask Dataset and Methodology for East/West Greenland, 1972-2019}

\Author[1]{Daniel}{Cheng}
\Author[1]{Yara}{Mohajerani}
\Author[2]{Michael}{Wood}
\Author[1]{Isabella}{Velicogna}
\Author[2]{Eric}{Larour}
\Author[1]{Wayne}{Hayes}

\affil[1]{University of California at Irvine, Irvine CA, USA}
\affil[2]{Jet Propulsion Laboratory, California Institute of Technology, Pasadena CA, USA}

\runningtitle{TEXT}

\runningauthor{TEXT}

\correspondence{Daniel Cheng (dlcheng@uci.edu)}

\received{}
\pubdiscuss{} %% only important for two-stage journals
\revised{}
\accepted{}
\published{}

\maketitle

\begin{abstract}
We present Calving Front Machine (CALFIN), a dataset of calving front masks for glaciers along West Greenland. The dataset is generated from Landsat imagery over the period 1972 to 2019. This dataset is unique in scope, and provides new constraints on glacial evolution over the time period. The current iteration offers a new opportunity to explore previous trends and validate existing models, enabling more accurate predictions moving forward.

The dataset is contains data that is automatically generated. We generate the vectorized calving fronts from raw Landsat imagery. Our method utilizes deep learning in the form of a neural network. This approach builds on existing work \citep{mohajerani2019} \citep{zhang2019} \citep{baumhoer2019}. The network itself is derived from U-Net/DeeplabV3+ Xception architectures \citep{ronneberger2015} \citep{chen2018} . Additional post-processing techniques allow our method to achieve accurate and useful segmentation of raw images into Shapefile outputs. This methodology is uniquely robust to clouds, illumination differences, ice mélange, and Landsat-7 scan-line errors/data coverage gaps.

We perform an analysis of CALFIN results, which approach human levels of accuracy in comparison to manually delineated fronts. Additionally, we perform a model inter-comparison to evaluate the robustness of CALFIN's performance and cross-validate it against existing methodologies. %TODO/Save for future paper? We show the applicability of CALFIN's methodology to SAR data, Antarctic glaciers, as well as non-marine terminating glaciers.

At this stage, we seek feedback from the community and welcome any critiques or questions regarding the dataset and/or our methods. This work was conducted as a collaboration between NASA’s Jet Propulsion Laboratory and the University of California, Irvine.
\citep{ronneberger2015}
\citep{iglovikov2018}
\citep{chollet2016}
\citep{chen2017}
\citep{chen2018}
\citep{bjork2015}
\citep{xie2015}
\citep{garcia2012}

\end{abstract}

\introduction
%Introduction
The evolution of Greenland's tidewater glaciers is an important constraint on the evolution of the Greenland Ice Sheet as a whole. Likewise, changes in the Greenland are important in tracking and predicting changes in the climate overall. Constraining Greenland's glacial evolution is thus an important part of improving our understanding of Earth's climate.

%Comment out subsection headers?
\subsection{Motivation}
One such constraint on glacial evolution is the position of glacial calving fronts over time. However, delineating the calving fronts of marine-terminating glaciers is typically a time-intensive manual process. As a result, many glaciers receive less labeling than is ideal, or none at all. Additionally, existing glaciers that do receive annual labeling do not capture intra-annual variability. 

The need for an improved methodology is apparent. An automated methodology allows for the solution to previously stated issues. However, the automation of glacial calving front delineation is non-trivial. Confounding issues - such as cloud cover, ice mélange, shadowing,  - present an impediment to naive techniques such as edge detection \citep{paravolidakis2016} and texture analysis \citep{malik2001}. Ultimately, emerging techniques in computer science provide a promising approach to this problem. More specifically, machine learning and deep neural networks provide a robust, scalable, and accurate method to automatically delineate tidewater glacial calving fronts.

\subsection{Methodology}
In this study, we evaluate automated methods of delineating glacial termini. The glaciers studied are located along East/West Greenland. They include Helheim, Kangerlussuaq, Kong Oscar, Hayes, Rink Isbrae, Upernavik, Jakobshavn, Kangiata Nunata, and 58 other nearby glaciers. The intra-annual time series studied spans from 1972 to June 2019. Our source data is the Landsat Near Infrared (NIR) band.

We determine that convolutional neural networks present the most promising automated methodology. We determine that the UNet-inspired DeeplabV3+ architecture, with Xception backbone, is the most promising neural network architecture. We release a modified version of the DeeplabV3+ network, along with the final weights we use for data production. We release a set of data products, Calving Front Machine (CALFIN), which consists of both calving front masks as well as Shapefile polylines for the 88 glacial basins along East/West Greenland.

\subsection{Existing Work}
Existing efforts have been made by ESA's climate Change Initiative to provide calving front locations for 26 Greenlandic basins, from 1990-2016\citep{enveo2017}. Additionally, there are growing efforts to provide a unified database of manually delineated calving fronts. Nonetheless, the constant addition of new data, as well as the current scarcity of shared data, implies a consistent and repeated need for new data assimilation efforts.

We evaluate existing work in the field, performed by Mohajerani, Zhang, and Baumhoer. These studies offer the potential to cross-validate the viability of our own methods.

\subsection{Takeaways}
Our main takeaway is the viability of generalized neural networks for automated calving front detection. Specifically, a well trained network is able to approach human levels of accuracy in picking out arbitrary glacial calving fronts. This demonstration of learning also lends credence to this methodology as a viable approach to other data assimilation tasks.

Our key goal is to provide high spatial accuracy, dense temporal resolution, and long time series calving front masks for the cryospheric/climate modeling community. We look forward to fulfilling this goal as we continue to improve our method and release additional data moving forward.

\section{Data - Source and Preprocessing}
This study focuses on the automated data assimilation of remote sensing data. In this section, we describe the following: we evaluate data sources with high spatio-temporal resolution; after selecting Landsat as our data source, we describe the preprocessing methods required for input into our neural network processing step.

\subsection{Data - Source}

\begin{wrapfigure}{r}{9.0cm}
\noindent
\begin{minipage}{9.0cm}
    \caption{A comparison of the data sources available for use. Long time series, high resolution, high repeat cycle attributes are desired, in that order. Italicized entries represent optimal sources within each attribute. }
    \label{tab:table-data_source}
    \resizebox{9.0cm}{!}{
    \begin{tabular}{|c|c|c|c|c|}
    \hline
    \multicolumn{5}{|c|}{\textbf{Potential Data Sources}} \\ \hline
    \textbf{Name} & \textbf{Resolution(s)} & \textbf{Time Series} & \textbf{Repeat Cycle} & \textbf{Sensor} \\ \hline
    Landsat & 30m, 60m & \textit{1972-present} & 16 day & Optical \\ \hline
    Terra (MODIS) & 250m, 500m, 1000m & 1999-present & \textit{1, 8, 16 day} & Optical \\ \hline
    Sentinel & 10m, 20m, 60m & 2014-present & 10, 12 day & SAR \\ \hline
    TerraSAR-X & \textit{1m, 3m, 6m} & 2007-present & 3-11 day & SAR \\ \hline
    
    \end{tabular}
    }
\end{minipage}

\begin{minipage}{9.0cm}
    \includegraphics[width=9.0cm]{all_Landsat_bands_annotated.png}
    \caption{Landsat band availability overlaid a graph of atmospheric transmission percentages for various wavelengths. The Near-Infrared The NIR band (highlighted in pink) benefits from both long time series availability, as well as high atmospheric transmittance.}
\end{minipage}
\end{wrapfigure}


We evaluate several potential dataset sources that provide raw data from which we assimilate calving front positions.

We constrain our input to be based on subsets of a single band. Part of this was due to computational constraints, as larger/multiband inputs result in longer processing times and more hardware requirements. Another consideration is the diminishing returns of adding additional bands. Since pixel information is correlated across different bands, and since a single band image already shows any discernible calving fronts, additional band information was deemed unnecessary.

%Insert landsat band overlap table
%https://landsat.gsfc.nasa.gov/landsat-9/landsat-9-spectral-bands/
We pick the Near Infrared (NIR) (.77-1.1um) wavelength band. This is based on evaluating  Landsat 1 - 8 band commonality, and choosing the band with the longest time series availability. We then pick the band with the highest atmospheric transmittance, which allows us to "look past" light cloud cover (See Figure 2). We initially hypothesized that using a common band is beneficial, as different spectral bands may exhibit features differently, and thus negatively impact detection accuracy. However, in practice (see 7.3 Discussion - Inter-model Comparison), the band selection is inconsequential as long as calving fronts are visible.


%%FIX THESE FIGURES - UPDATE TEMPORAL RESOLUTION & ADD TO SPATIAL COVERAGE MAPS


\begin{wrapfigure}{r}{12.1cm}
    \noindent
    \begin{minipage}{4.8cm}
        \includegraphics[width=4.8cm]{time-coverage.png}
        \caption{Number of images across the years for 6 selected glaciers. We evaluate glaciers across a longer time series than any existing studies.}
    \end{minipage}
    \hspace{0.15cm}
    \begin{minipage}{7.15cm}
        \centering
        \includegraphics[width=7.15cm]{spatial-coverage.png}
        \caption{Spatial distribution of 6 glaciers along West Greenland. We study glaciers with large flow velocities and wide spatial distribution.}
    \end{minipage}
\end{wrapfigure}

\subsubsection{Time Series Coverage}
Landsat availability per year, for all 6 basins. 
Gaps are due to clouds or lack of classifier confidence.
Color key shows rough number of observations per year.
See Figure 3.

\subsubsection{Spatial Coverage}
CALFIN data availability along West Greenland, for the highlighted basins, over velocity map \citep{nagler2015}.
Basins are primarily selected for study potential/high velocities.
Basins are secondarily selected for equal sampling of coastline.
See Figure 4.

\subsection{Data - Preprocessing}
Throughout our study, we developed a pipeline that automates much of the data preprocessing that is required for this task. This pipeline involves the following steps: Data source collection, GeoTIFF/domain subsetting, Low quality/clouded image pruning, Subset standardization, Detail Enhancement.
Once these steps are complete, we proceed with processing in the neural network processing step.


\subsubsection{Data - Preprocessing - Collection}
As a first step, we collect the input raster images that for which we want to evaluate. We utilize all available input image time steps with less than 20\% cloud cover across the entire area. We accumulate 4776 Landsat rasters, from which we subset individual glacial domains. 

\subsubsection{Data - Preprocessing - Subsetting}
To begin subsetting, we define the domain of a glacial basin, which should fully encloses the calving front being extracted. We encode the domain as a rectangular Shapefile polygon. Next, we automatically subset the raster for every time step which we want to evaluate for the domain. We repeat this process for each basin to be studied. While this requires manual input, it only needs to be done once, as the domains will be reused across multiple subsetting operations.
%For rasters and domains in West Greendland, we reproject to WGS 84 / UTM zone 21N (EPSG:32621). For East Greenland, we use WGS_1984_UTM_Zone_24N (EPSG:32624)

\subsubsection{Data - Preprocessing - Pruning}
After subsetting, we automatically prune images that are ill-suited for further processing. First, we determine the amount of NODATA pixels present in the subset, and remove it from evaluation if it exceeds a predetermined threshold (>30\%). This allows us to process images with Landsat 7 scan-line errors and domains along raster boundaries, while still filtering out largely out-of-bounds subsets. This prevents them from being unnecessarily and inaccurately processed. Also, if an accompanying Quality Assurance band is present, the same filtering procedure is performed to eliminate images with high cloud cover, for the same reasons. We accumulate 20,029 image subsets, spread across 66 glacial domains.

\subsubsection{Data - Preprocessing - Standardization}
Then, we resize the image to a standardized, square resolution. We convert the subsets from their native GeoTIFF formats to a standardized 256x256 PNG image. While larger networks The GeoTIFF subsets are utilized for rescaling and georeferencing the Shapefile after processing. This step can introduce error into the delineation, which we address by defining domains as close to the specified square resolution whenever possible.
%We found through empirical testing that this input resolution is optimally balanced considering accuracy of the output and computational bottleneck. 

\subsubsection{Data - Preprocessing - Detail Enhancement}
Lastly, we perform image transformations to enhance detail and provide the processing step with more information. We found through empirical testing that this step specifically benefits raw images with heavy shadowing. This benefit emerges since these images contain details which are otherwise undetectable by the filters used in the processing step. We utilize two non-linear transformations, the Pseudo-HDR Toning and Shadows and Highlights enhancements. These enhancements are performed with default settings in Adobe Photoshop, but we aim to write an open-source equivalent in Python. We concatenate the results of the two transformations with the raw image. This creates 3-channel RGB input images that contains information that can be utilized by the next step. 

At this point, the images are ready for processing into calving front masks.

%Jumping to final implementaiton - should we fill in-between networks? Probably should skip to here - no sense in covering everything that was done, too long
%NOTE: I moved the edge detection/texture analysis/neural network explanation down and commented it out for now
\section{Methodology - Processing}
We perform the core processing step by passing images through the Calving Front Machine Neural Network (CALFIN-NN). As a convolutional neural network that inherits from the U-Net family of architectures, CALFIN-NN is capable of learning abstract image features, and outputting confidence masks of where it detects coastlines  and calving fronts. Importantly, it generalizes to new data automatically. This key capability is the foundation of most other automated methods in this field, including those by Zhang \citep{zhang2019}, Mohajerani \citep{mohajerani2019}, and Baumhoer \citep{baumhoer2019}. 

Our network builds upon this work, and utilizes a modification of Google's DeepLabV3+ Xception image segmentation network. With our customized architecture and training regimen, CALFIN-NN is capable of handling inputs with different scales/resolutions, heavy shadowing, ice mélange, light cloud cover, and Landsat 7 scan-line errors. Together, these novel innovations bring the state-of-the-art in image segmentation to the cryosphere community. The following section describes the details of our network model, including the iterative process of testing, evaluation methods, and our final training regimen.

\subsection{Methodology - Processing - Model Architecture \& Details}
CALFIN-NN takes in 3-channel pre-processed images, and outputs 2-channel images containing the edge and the land ice/ocean mask. 


\begin{figure}[t]
\includegraphics[width=18cm]{arch_final.png}
\centering
\end{figure}
%FIGURE HERE: CREATE NETWORK FIGURE

%List out features of Deeplab first
-Xception modules and Atrous Spatial Pyramidal Pooling capture multi-scale features
-Built for image segmentation/classification, but needs work for recognizing thin/line like features like calving fronts

%List modifications to the above
-Modification of the 6, 12, 18 ASPP branches to 1, 2, 3, 4, 5
-Usage of Xception 65 layer base implementation instead of default header module in DeepLabV3+
-Modified output: 2 channel output for mask and edge simultaneously
-Reduced weight size: 29m parameters, ~400MB


%Features
-224x224 image size: 
-3 channel input: Our network intakes a 3 channel image input.
    -R channel: Raw image, directly taken from the Landsat domain subset.
    -G channel: High-Definition Range Toning image, processed in Adobe Photoshop.
    -B channel: Shadows and Highlights enhancement image, processed in Adobe Photoshop
-2 channel output:
    -R channel: Edge mask. 
    -G channel: Ice/ocean mask.


%Show an image here?
%Problem: low accuracy with higher resolution.
Solution: We remade our training data at higher resolutions and enlarged the edges of the detected fronts to address scaling issues. Effectively, we made a larger target, and thus made it easier to achieve, without sacrificing accuracy.

%Problem: Memory-effects/overfitting.
Solution: We added data augmentation to enforce learning more general features. These included image translation, noise addition, and detail-preserving image filters like emboss/CLAHE.

%Problem: Validation accuracy did not reflect test accuracy.
Solution: We added additional training images from all 60 additional domains, including some from East Greenland.

\section{Post-Processing}
At this stage, the raw pixel mask output of the CALFIN-NN must be post-processed in order to create a useful data product. However, this task is non-trivial, and is subject to several unique constraints. We describe the various problems we encounter, and offer our unique solutions for each.
\begin{itemize}
\item The pixel mask output by CALFIN-NN is often imperfect. We develop a unique algorithm to infer the correct coastline boundary.
\item The calving front must still be isolated from the coastline that is output by CALFIN-NN. We utilize fjord boundary masks and image analysis techniques to accomplish this.
\item The isolated calving fronts must then be isolated and refined, as the fixed input/output resolution of CALFIN-NN results in error associated with subset rescaling. We address this by performing a pseudo box-regression, and re-processing zoomed-in subsets that are centered on each isolated calving front.
\item Each refined calving front must still be transformed into a georeferenced Shapefile for further use. This is comparatively easy to solve using GDAL and the original GeoTIFF subsets, but still must be performed.
\end{itemize}

\subsection{Post-Processing - Pixel Mask to Coastal Polyline}
The first problem is that the raw pixel mask is often imperfect. Currently, CALFIN-NN cannot always completely determine the calving front in an arbitrary image. As a consequence, traditional vectorization methods using OpenCV or GDAL will not work with the imperfect, non-closed contours seen in  CALFIN-NN's output. However, the nature of its inaccuracies are predictable. Thus we exploit the characteristics of CALFIN-NN's output to compensate for its specific inaccuracies. $show examples here!$

To address this first constraint, we develop an algorithm that finds the polyline representing the coastline in the pixel mask. This is implemented by converting each pixel in the mask to nodes in a graph, and finding the single longest path in the graph's minimum spanning tree. This path consistently corresponds to the the coastline edge. Note that this algorithm is not guaranteed to find the correct calving front, as is still limited by the output of processed by CALFIN-NN.

A detailed explanation of the algorithm follows below.

%Include figure of pipeline here

\begin{enumerate}
    \item First, calculate the euclidean distances between each node and every other node, creating distance matrix D.
    \item Then for each point, find the k-nearest neighbors using distance matrix D. K is generally chosen to be the maximum of some minimum number of nodes (we choose 4) and some percentage of the total number of nodes (we choose 20\%). The choice of K for following outlier detection step.  This step ensures continuous lines, removes some outlier noise, while still allowing for large gaps in the pixel mask graph to be crossed.
    \item To further address outliers and spurious detections, we remove any nodes that mean distance to its neighbors is itself an outlier. To compute the outliers of mean neighbor distance, we use the robust Modified Z-score method with Median Absolute Deviation \citep{garcia2012}. We eliminate any node whose mean neighbor distance exceeds a z-score of 10. We determine this threshold through empirical testing. 
    \item Next, we use the k-nearest neighbors graph to construct a undirected weighted minimum spanning tree (MST).
    \item Lastly, we find the longest path in the MST. This can be done by performing 2 depth-first searches (DFS), with each DFS finding one endpoint along the longest overall path. This longest overall in the MST consistently corresponds with the calving front detected by CALFIN-NN.
\end{enumerate}

\subsection{Post-Processing - Coastline to Calving Front}
The second problem is to isolate the calving front from the coastline polyline output by the previous post-processing step. This problem occurs because CALFIN-NN is trained to detect ice/ocean boundaries, but not yet how to isolate the fronts themselves. Therefore, work must be done to remove edges detected along the fjord boundaries.

We address this second constraint by creating 66 fjord boundary masks, one for each domain. We then use these masks to extract the front from the full coastline edge mask that is output by the neural network. Still, due to coastline variations, the static fjord boundary mask does not always isolate the calving front. Thus we develop another algorithm to contract the boundary mask until only the calving front remains. We exploit the fact that the detected coastline is parallel to the fjord boundaries, while the calving front is usually perpendicular to both. 


A detailed explanation of the algorithm follows below.

%Include figure of pipeline here

\begin{enumerate}
    \item TOFIX
\end{enumerate}
%show erosion steps here, with highlight around optimal

\subsection{Post-Processing - Calving Front Reprocessing}
The last problem is to correctly transform the vectorized polyline to a geo-referenced Shapefile. While this problem is more easily solvable, it must still be performed in order to generate the desired data product. Additionally, there may be multiple fronts depending the specific domain and time frame. %Show example

We address this last constraint by first isolating individual calving fronts by performing a connectivity analysis. For each isolated front, we perform the Pixel Mask to Coastal Polyline postprocessing step again to retrieve a polyline. Then we use GDAL and the GeoTIFF subsets from the preprocessing step to re-scale the polyline, georeference it, and export a Shapefile data product.

\subsection{Post-Processing - Calving Front to Shapefile}
The last problem is to correctly transform the vectorized polyline to a geo-referenced Shapefile. While this problem is more easily solvable, it must still be performed in order to generate the desired data product. Additionally, there may be multiple fronts depending the specific domain and time frame. %Show example

We address this last constraint by first isolating individual calving fronts by performing a connectivity analysis. For each isolated front, we perform the Pixel Mask to Coastal Polyline postprocessing step again to retrieve a polyline. Then we use GDAL and the GeoTIFF subsets from the preprocessing step to re-scale the polyline, georeference it, and export a Shapefile data product.


\section{Results}
We generate result that are two-fold in nature. First, we release the calving front data we generate throughout the study, which consists of approximately 1747 manually delineated calving fronts across 66 Greenlandic glacial domains. Second, we release the implementation of CALFIN-NN to the scientific community for use, study, and further development.
Data outputs:
	CALFIN Neural Network
		Weights, Architecture
	Calving Fronts
        Level 0: Raw subsets, neural network masks
        Level 1: Shapefiles
        Level 2: Data/Science products?? Analysis
List of all domains:

%Show layered fronts for 1 or 8 domains
%Show accuracy metrics, list numbers of subsets

%Retrieve graphs from pyplot, showing mean deviation from front histograms
Approx 2k high res, hand-made/verified data (<30m accuracy from hand drawn line, but should be cross validated with other's data - see inter-comparison section). Derived from training data. 66 domains, ~4-50 data points for each domain
Approx 20k unverified test data ~40-500 data points for each domain
Shapefile

\subsection{Results - Error Analysis}


%Show graph of meters per pixel vs accuracy
%Show per domain accuracy graph or table

%
mean deviation (averaged over points): 102.08 meters
mean deviation (averaged over images): 102.27 meters
mean deviation (averaged over points): 2.54 pixels
mean deviation (averaged over images): 2.65 pixels
image skip count: 27 front skip count: 34 no detection skip count: 5 confidence skip count: 29 
total fronts: 140 
Detection Rate: 82.24\% images detected with fronts (125/152)
3-pixel wide edge mean Jaccard index (Intersection over Union): 0.5281
Land/ice-ocean/mélange mean Jaccard index (Intersection over Union): 0.977

We have two primary methods of evaluating the predicted output of any calving front against the ground truth labeling.
The first method is the standard Intersection over Union, or Jaccard score. This metric evaluates the degree of overlap between the predicted and ground truth pixel masks of the calving front. 

The second method is the more domain specific Mean Distance from the Front, which is the same metric utilized by Mohajerani et al.\citep{mohajerani2019}. This metric evaluates the average distance between closest points between predicted and ground truth fronts. Conceptually, this method resembles numerical integration of the area between two curves, divided by the average length of the curves. 

51.36\% weighted IoU score (25/26 edge weight, 1/26 ice/ocean mask weight)
target: ~200m mean deviation from the front. min mean in Kangerlussuaq at ~1.5 pixels on validation set. What this network lacks in accuracy, it makes up for in generalizability - no other network has tested consistently on this number of domains.

%\subsection{Results - Evaluation and Error Analysis}
%To evaluate the accuracy and robustness of models during our %search, we treat the processing step as a binary %classification problem. To evaluate this problem, we use the %Intersection of Union (IoU) metric. Also known as the Jaccard %index, this metric measures the number of correct predictions %divided by the union of ground truth and predicted values. %This is a standard method, is robust to skewed data, and is %well suited to evaluating the accuracy of this network and the %processing step as a whole.

\section{Results - Time-series Generation}
As an auxiliary result, we output the time-series plots of calving front over individual domains, for the span 1972- June 2019. 

\section{Discussion}
We describe information, materials, and methods that are auxiliary to the data and methodology described in this study. This includes the following topics:
\begin{itemize}
    \item We document how our neural network was trained, to encourage transparency and reproduciblility.
    \item We talk about the existing work in this field, specifically surrounding deep learning applied to calving front/coastline extraction.
    \item We perform a model inter-comparison with Mohajerani et al., to study the robustness of both models and their evaluation metrics.
\end{itemize}

\subsection{Discussion - Neural Network Development and Training}
\subsubsection{Training Data}
In order to train our network, we create training data, which consists of preprocessed inputs and ground truth images. This training data consists of 1744 images pairs, with 1555 pairs for training and 189 pairs for validation. 
\subsubsection{Network Architecture Search}
We began our search using the same basic UNet architecture as found in Zhang et al.\citep{zhang2019}, Mohajerani et al.\citep{mohajerani2019}, and Baumhoer et al.\citep{baumhoer2019}. During our initial development, we varied the UNet's depth, number of filter layers, and input size. However, as we added more domains and poorer quality images, it became apparent that the network architecture was limited. 
At this point, we decided to evaluate other state-of-the-art image segmentation networks. We found Google's DeepLabV3+ Xception network to be the highest performing architecture on common benchmark segmentation datasets such as PASCAL-VOC. The DeepLabV3+ Xception architecture shows improvements in multi-scale feature extraction at a reasonable computational cost as compared to UNet derived architectures. Additionally, its larger size gives it the capacity to learn much more abstract features - this improvement is 

To improve accuracy further, we modified the DeepLabV3+ Xception network. 

\subsubsection{Training Regimen}
We trained the network over 80 epochs, with 4000 batches per epoch, and 8 images per batch. We utilized a K40 Nvidia Tesla GPU, with each epoch taking 7540 about 126 minutes to complete, or about 1 week to complete all 80 epochs. We utilize the Adam optimizer, which automatically computes optimal learning rates per parameter. We do use a modified Adam optimizer that accumulates the gradient over 2 batches so that our effective batch size is 16. Additionally, it clips the learning rate at 1e-4, to prevent exploding gradients during training/backpropagation.
We utilize Exponential Linear Units (ELU) over ReLU as our activation function, to prevent vanishing gradients. Our loss function is a weighted combination of binary cross entropy (BCE) and two Jaccard/Intersection-over-Union (IoU) calculations. 
%Insert equation here
This loss function heavily penalizes incorrect predictions (a property of BCE/IoU), heavily favors correct predictions (a property of IoU), and is differentiable (a property of the natural log). Additionally, the weighting heavily favors correct coastline/edge mask predictions, which is critical for increasing calving front prediction accuracy.
\subsubsection{Data Augmentation/Test-time Augmentation}

\subsection{Discussion - Existing Work}
Our work was performed alongside - and builds on - existing work done in the field.

Mohajerani et al.\citep{mohajerani2019} provides a similar case study using the same type of deep neural network architecture to detect calving fronts. His study is performed on the Greenlandic glacial basins Jakobshavn, Helheim, Sverdrup, and Kangerlussuaq. Mohajerani's methodology displays promising steps towards generalizability and has been preeminent in the field.

Zhang et al.\citep{zhang2019} performs an analysis similar to Mohajerani, albeit in a more specific case study using SAR data of Jakobshavn. The applicability of neural networks as a general methodology for calving front analysis is supported by its successful usage here. 

Baumhoer et al.\citep{baumhoer2019} evaluates modified UNet architectures, as applied to SAR data of Antarctica. Her studies incorporate large spatial context in order to capture whole-coastline delineations. The prospect of larger networks on the order of 768x768 pixels offers the promise of higher resolution/accuracy outputs.

Our methodology shares the same basic approach with the above. We utilize an updated neural network architecture - DeeplabV3+ Xception - that improves upon the base UNet design. Furthermore, we use additional post-processing steps to make the detection more accurate.

\subsection{Discussion - Inter-model Comparison}
We perform an inter-comparison between the performance of CALFIN with respect to the study conducted by Mohajerani et al. This  allows for a robust evaluation of the different models and error quantification metrics. To perform this task, we process the validation data used by each other's models, and compare the results.
%TODO
%have Yara/Mike insert results of preprocessed Helheim on Yara's network here?

\begin{figure}[t]
\includegraphics[width=18cm]{helheim_plots_intercomp.png}
\caption{The graphs above provide verification information for a single test image from the set of 10 used in Mohajerani et al. \textbf{b)} is an RGB image containing the raw image (R), a High Dynamic Range toned image (G), and a Shadows/Highlights enhanced image (B). This prerocessed image is then fed into CALFIN-NN. \textbf{c)} is an RGB image, containing the coastline/edge mask (R) and the land/ice mask (G). \textbf{e)} compares the fronts from our method (R), the ground truth (G), and Mohajerani et al. (B). The Jaccard index calculates the overlap between our method and the ground truth as a percentage from 0 to 1. \textbf{f)} is a histogram that quantifies the error between our method and the ground truth. The error is quantified in terms of distance between each pixel in one line and the closest point in the other line.}
\centering
\end{figure}

\begin{figure}[t]
\includegraphics[width=16.0cm]{helheim_histo_intercomp.png}
\caption{Distances between predicted points and the true front. Calculated over the 10 images from Mohajerani et al. Compare mean deviations from our method (102.52m) and Mohajerani et al. (96.31m). While our method is not as performant on this subset of images, the ability of our network to other domains and conditions is an acceptable tradeoff.}
\centering
\end{figure}

Across the all 10 test images in Mohajerani et al., we attain a 102.52 meter (2.10 pixel) mean distance between the predicted and the ground truth fronts. This metric is calculated by finding the closest points from every other point between the predicted and the ground truth front pixel masks. We see that this approaches the level of accuracy achieved in the original study, which was 96.31 meters (1.97 pixels). While our method does not exceed this level of accuracy, it was still able to approach it with no further training done. We conjecture that the relatively higher resolution and the lack of wider context in the input image results in this performance gap.
%To validate this conjecture, we reevaluate our Helheim validation images at higher resolution subsets, but with the added context of the nearby terrain and surroundings. %TODO?



Furthermore, note that \citep{mohajerani2019} obtained the mean error estimate by breaking each delineated front to 1000 smaller segments within a small buffer from the fjord walls and calculating the mean deviation between the segments of the true and delineated fronts. Here we calculate the errors by getting the mean distance between each pixel of the delineated front and the closest pixel of the true front. This does not require the fronts to have the same number of pixels, as several pixels can be mapped onto one pixel. It is important to emphasize that the error results can be very sensitive to the error evaluation methodology. By comparing pixels directly, we avoid comparing line segments far from each other due to different lengths of the delineated and true fronts. In that sense, the line-segment methodology of \citep{mohajerani2019} provides a more conservative estimate as it relies on line segments being close to each other.

\textcolor{red}{talk about other differences: landsat stripes not included in training of M19 (Mohajerani et al 2019), M19 used different spectrum band for training, fewer training instances in M19, maybe talk about post-processing difference (least-cost path through front-segmented output, etc.}

Overall, this inter-comparison supports our hypothesis that our methodology is generalizing well and is sufficiently accurate.

\conclusions[]Conclusion \& Future Work]
The calving front data products are being released on rolling basis at www.ics.uci.edu/~dlcheng. %datadryad or NSIDC?
The neural network model is being released on https://github.com/daniel-cheng/CALFIN.

Overall, we accomplished our goal of implementing a method for the automatic calving fronts delineation. Our method utilizes the cutting-edge in deep learning architectures. Our method achieves robustness to minor cloud cover, Landsat 7 scan line errors, and illumination changes. We address issues with generalization through use of additional training data and an improved neural network architecture. We are competitive among existing work being done in this field.  

Future work includes extending CALFIN-NN to integrate 

Our data augmentation, network architecture, and post-processing methods all contribute to the success of our methodology. Ultimately, this work showcases the state-of-the-art in field of deep neural networks as applied to automated calving front detection, and provides a new database of calving fronts for the scientific community.

\subsection{Supplement}


\codedataavailability{
    The code used to automate the CALFIN pipeline is freely available here: https://github.com/daniel-cheng/CALFIN
    
   The data generated by CALFIN, including Level 0 and 1 data products, are freely available here: (datadryad link)
}


\authorcontribution{
    DC developed the code/model, carried out the data processing, and wrote majority of the manuscript.
    YM performed the model inter-comparison and assisted with the writing of the manuscript.
    EL provided direction for the overall study.
    IV assisted in organizing collaborators and model inter-comparison.
    MW performed the data preprocessing for the model inter-comparison.
    WH provided direction on the processing methodology, post-processing algorithms, and error analysis.
    EL, IV, and WH reviewed the manuscript and evaluated the results.
}

\competinginterests{
    The authors declare no competing interests.
}

\begin{acknowledgements}
    This work was conducted as a collaboration between NASA’s Jet Propulsion Laboratory and the University of California, Irvine. 
\end{acknowledgements}

\bibliographystyle{copernicus}
\bibliography{references.bib}  %%% Use the external .bib file (using bibtex).

\end{document}